# yume-pdq

A hand-vectorized implementation of the Facebook Perceptual Hash ([PDQ](https://github.com/facebook/ThreatExchange/tree/main/pdq)) estimation algorithm that prioritizes throughput over precision.

Warning: This should be fully functional to my standards, but I am holding off publishing it to crates.io for a few days to finalize some design decisions.

TODO: Write a piping binary suitable for ffmpeg.

## Design Goals

Be _accurate enough_ for high-throughput screening. At present, a test image usually result in ~12 bits different from @darwinium-com's [pdqhash](https://crates.io/crates/pdqhash) reference implementation, the official docs require 10 bits to be considered "correct". However the threshold for matching is 31 bits so we consider this not important for the purpose of matching.

Parallelize well up to the memory bandwidth limit.

Not bit-identical to the reference implementation.

Zero dependencies in the final binary (including statically linked crates).

No-std support.

## Benchmark

Generated by criterion on an AMD Ryzen 9 7950X (Zen 4) with two 32GiB DDR5 6000MT/s RAM, empty cells below means there are no hand-tuned implementation for that operation.

|                                                             |                                                 |
| ----------------------------------------------------------- | ----------------------------------------------- |
| ![Benchmark overall operations](bench-plot/overall_ops.jpg) | ![Benchmark overall](bench-plot/overall.jpg)    |
| ![Benchmark sub-operations](bench-plot/sub.jpg)             | ![Benchmark hash-flipping](bench-plot/flip.jpg) |



## Accuracy on test set

| Image                                                 | Kernel  | Distance vs pdqhash lib | Quality | Distance vs Reference |
| ----------------------------------------------------- | ------- | ----------------------- | ------- | --------------------- |
| aaa-orig.jpg (real photo, official test vector)       | AVX2    | 6/256 (2.3%)            | 0.966   | 4/256 (1.6%)          |
|                                                       | AVX512  | 6/256 (2.3%)            | 0.966   | -                     |
|                                                       | Default | 6/256 (2.3%)            | 0.966   | 4/256 (1.6%)          |
| anime.png (it's anime)                                | AVX2    | 16/256 (6.2%)           | 0.556   | 10/256 (3.9%)         |
|                                                       | AVX512  | 16/256 (6.2%)           | 0.556   | -                     |
|                                                       | Default | 16/256 (6.2%)           | 0.556   | 10/256 (3.9%)         |
| music.png (Music Video screenshot)                    | AVX2    | 10/256 (3.9%)           | 0.493   | 8/256 (3.1%)          |
|                                                       | AVX512  | 10/256 (3.9%)           | 0.493   | -                     |
|                                                       | Default | 10/256 (3.9%)           | 0.493   | 8/256 (3.1%)          |
| neofetch.png (neofetch screenshot, low-entropy image) | AVX2    | 27/256 (10.5%)          | 0.642   | -                     |
|                                                       | AVX512  | 27/256 (10.5%)          | 0.642   | -                     |
|                                                       | Default | 26/256 (10.2%)          | 0.642   | -                     |

## License and attributions

This crate is licensed under the Apache 2.0 license.

Special thanks to [@darwinium-com](https://github/darwinium-com) for their [pdqhash](https://crates.io/crates/pdqhash) crate, which was a great source of inspiration and the reference kernel
was ~~shamelessly~~ copied almost verbatim from them.

> If it works why rewrite it?
>
> \- Me, probably