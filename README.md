# yume-pdq

A hand-vectorized implementation of the Facebook Perceptual Hash ([PDQ](https://github.com/facebook/ThreatExchange/tree/main/pdq)) estimation algorithm that prioritizes throughput over precision.

## Pipeline Overview

![Pipeline Overview](pipeline_overview.png)

## Design Goals

Be _accurate enough_ for high-throughput screening. At present, the official docs require 10 bits when quality > 0.8 to be considered "correct" and we are currently right on the border (see [Accuracy on test set](#accuracy-on-test-set)). However the threshold for matching is 31 bits so we consider this not important for the purpose of matching.

Parallelize well up to the memory bandwidth limit.

Not bit-identical to the reference implementation.

Zero dependencies in the final binary (including statically linked crates).

No-std support.

## Binary usage

Prerequisites:
- Rust toolchain (2024 edition or newer (1.85.0 or newer))
- A CPU that is supported by the Rust toolchain (of course)
- To use f32x8 SIMD kernel, you need an x86_64 CPU with AVX2 and FMA support
- To use f32x16 SIMD kernel, you need an x86_64 CPU with AVX512F support (usually every single AVX512 CPU supports this)

Compilation for your own CPU (AVX2 if available, falls back to an auto-vectorized scalar kernel) is done usually with:

```bash
RUSTFLAGS="-Ctarget-cpu=native" cargo build --release --features "cli"
```

If you want a generic binary that only assumes AVX2 and FMA is available to use the optimized kernel, you can build with:

```bash
RUSTFLAGS="-Ctarget-feature=+avx2,+fma" cargo build --release --features "cli"
```

If your CPU has AVX512, you can also try (with a Rust nightly compiler):

```bash
RUSTFLAGS="-Ctarget-cpu=native" cargo +nightly build --release --features "cli avx512"
RUSTFLAGS="-Ctarget-feature=+avx512f" cargo +nightly build --release --features "cli avx512"
```

and see if it is faster, it may not be, especially with older generations of AVX512 CPUs, and it makes the final binary highly specific to your CPU (even other AVX512 CPUs may get #UD on your `-Ctarget-cpu=native` binary).


See [binary_usage.md](binary_usage.md) or the CLI help menu for details and practical examples.

## Python usage

See [integration/python.py](integration/python.py) for an example of how to use this library from Python.

```py
python integration/hash.py test-data/aaa-orig.jpg                                                                               09:42:59
Image: test-data/aaa-orig.jpg
Quality: 1.000
Threshold: 12.554
Hash: 58f8f0cee0f4a84f06370a32038f67f0b36e2ed596621e1d33e6b39c4e9c9b22
Starting 1000 iterations
Finished 1000 iterations
Average Time taken: 6628.865 us
Average conversion time: 6546.036 us
Average hash time: 80.998 us
```

## Benchmark

### Formal

Generated by criterion on an AMD Ryzen 9 7950X (Zen 4) with two 32GiB DDR5 6000MT/s RAM, empty places below means there are no hand-tuned implementation for that operation (i.e. that operation is "downgraded" to the next most vectorized implementation).

|                                                             |                                                 |
| ----------------------------------------------------------- | ----------------------------------------------- |
| ![Benchmark overall operations](bench-plot/overall_ops.jpg) | ![Benchmark overall](bench-plot/overall.jpg)    |
| ![Benchmark sub-operations](bench-plot/sub.jpg)             | ![Benchmark hash-flipping](bench-plot/flip.jpg) |


### Empirical / End-to-end

#### Video Processing

Two different sources are used to test the end-to-end performance of the final CLI binary that ingest raw video frames.

Random source is generated by `yume-pdq random-stream`, FFMPEG SMPTE is a constant stream of SMPTE bars generated with:

```sh
ffmpeg -hide_banner -loglevel error -f lavfi -i testsrc=size=512x512:rate=1  -pix_fmt gray  -f rawvideo -
```

Finally each kernel is tested against both sources. FPS was collected by running `yume-pdq pipe --stats` and recording the output.

| Vectorization | Random Source | FFMPEG SMPTE |
| ------------- | ------------- | ------------ |
| AVX512        | 7600 fps      | 4050 fps     |
| AVX2          | 7600 fps      | 4100 fps     |
| Scalar        | 1600 fps      | 1500 fps     |

AVX2 was able to saturate the speed FFMPEG can generate SMPTE bars.

Additionally, the format of the output (hex, binary, or raw, or prefixed with a quality score) does not significantly affect the throughput except the 7600 fps cases.

#### Image Processing

When using the imagemagick `convert` command default resizing kernel (Mitchell-Netravali) is used, 1000 images are processed in 26 seconds.

```bash
for i in (seq 1 1000); ln -s (realpath test-data/aaa-orig.jpg) /tmp/test/$i.jpg; end

time convert 'test-data/*' -resize 512x512! -colorspace gray -depth 8 gray:-  | yume-pdq pipe -f 'hex+lf'

Executed in   26.01 secs    fish           external
usr time   47.76 secs    0.00 millis   47.76 secs
sys time    9.43 secs    2.77 millis    9.43 secs
```

## Accuracy on test set

The accuracy was done by writing unit tests that do pairwise comparison with either the "pdqhash" high level API or the 32-bit floating point reference implementation or the 96-bit floating point reference implementation.

Note higher distance to the `pdqhash` library is expected as they have mandatory preprocessing steps that cannot be slipped by the exposed API. The "reference" implementation is a more faithful pairwise comparison.

| Image                                                 | Kernel  | Distance vs pdqhash lib | Distance vs Ref32 | Distance vs Ref96 |
| ----------------------------------------------------- | ------- | ----------------------- | ----------------- | ----------------- |
| aaa-orig.jpg (real photo, official test vector)       | AVX2    | 6/256 (2.3%)            | 4/256 (1.6%)      | 4/256 (1.6%)      |
|                                                       | AVX512  | 6/256 (2.3%)            | 4/256 (1.6%)      | 4/256 (1.6%)      |
|                                                       | Default | 6/256 (2.3%)            | 4/256 (1.6%)      | 4/256 (1.6%)      |
|                                                       | Ref32   | 6/256 (2.3%)            | -                 | 0/256 (0.0%)      |
| anime.png (it's anime)                                | AVX2    | 16/256 (6.2%)           | 10/256 (3.9%)     | 10/256 (3.9%)     |
|                                                       | AVX512  | 16/256 (6.2%)           | 10/256 (3.9%)     | 10/256 (3.9%)     |
|                                                       | Default | 16/256 (6.2%)           | 10/256 (3.9%)     | 10/256 (3.9%)     |
|                                                       | Ref32   | 16/256 (6.2%)           | -                 | 0/256 (0.0%)      |
| music.png (Music Video screenshot)                    | AVX2    | 10/256 (3.9%)           | 8/256 (3.1%)      | 8/256 (3.1%)      |
|                                                       | AVX512  | 10/256 (3.9%)           | 8/256 (3.1%)      | 8/256 (3.1%)      |
|                                                       | Default | 10/256 (3.9%)           | 8/256 (3.1%)      | 8/256 (3.1%)      |
|                                                       | Ref32   | 10/256 (3.9%)           | -                 | 0/256 (0.0%)      |
| neofetch.png (neofetch screenshot, low-entropy image) | AVX2    | 27/256 (10.5%)          | 10/256 (3.9%)     | 11/256 (4.3%)     |
|                                                       | AVX512  | 27/256 (10.5%)          | 10/256 (3.9%)     | 11/256 (4.3%)     |
|                                                       | Default | 26/256 (10.2%)          | 10/256 (3.9%)     | 10/256 (3.9%)     |
|                                                       | Ref32   | -                       | -                 | 0/256 (0.0%)      |


## How?

This is a TODO as my blog post, but generally the gist is:

- Adjust the intermediate matrix size to make convolution fit perfectly on pixel centers.
- Precompute LUT for everything.
- Hand-optimized compute kernels to specific lane widths with optimal memory access pattern and register pressure.

## License and attributions

This crate is licensed under the Apache 2.0 license.

Special thanks to [@darwinium-com](https://github/darwinium-com) for their [pdqhash](https://crates.io/crates/pdqhash) crate, which was a great source of inspiration and the reference kernel
was ~~shamelessly~~ copied almost verbatim from them.

> If it works why rewrite it?
>
> \- Me, probably